{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# Kmart Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "*   Collect and arrange raw dataset from GitHub repo\n",
        "*   Process data (handle missing data, duplicates, junk data, engineer) for subsequent analysis\n",
        "* Generate pipeline to process the data\n",
        "* Generate dataset for subsequent analysis\n",
        "\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Set of CSV data from GitHub repo\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Cleaned and engineered dataset for subsequent analysis (the notebook was run on Colab, the data was downloaded manually and updated manually to the GitHub repo)\n",
        "* Pipeline to process the data that can be handled to a software engineer\n",
        "\n",
        "## Roadmap\n",
        "\n",
        "* Liase with data engineering to better understand data generation mechanism (not critical, but worth to add)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AbCnTnSqYP4"
      },
      "source": [
        "# Install and load packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3-FyjxCcEI0"
      },
      "outputs": [],
      "source": [
        "! pip install pandas==1.3.5\n",
        "! pip install matplotlib==3.5.0\n",
        "! pip install seaborn==0.11.2\n",
        "! pip install plotly==5.1.0\n",
        "! pip install feature-engine==1.4.0 \n",
        "! pip install scikit-learn==1.1.1\n",
        "! pip install pandas-profiling==3.3.0 \n",
        "\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTlHtCpocEI3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style(\"whitegrid\")\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tdAGw4Zwssu"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2oPUd1K_qCr"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oy-qxp1Hx6N5"
      },
      "source": [
        "Collect data from GitHub repo\n",
        "* **NOTE: we don't have clarity on the data generation mechanism**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "C75g-JX7tSTu",
        "outputId": "934a3b5f-c08a-4826-ee0c-2aae1671ed82"
      },
      "outputs": [],
      "source": [
        "df_raw = pd.DataFrame()\n",
        "for month in ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November',  'December']:\n",
        "  df_raw = df_raw.append( pd.read_csv(f\"https://raw.githubusercontent.com/jsc1535/K-Mart-Data-Analysis/main/Sales_{month}_2019.csv\") )\n",
        "\n",
        "df_raw.reset_index(inplace=True, drop=True)\n",
        "df = df_raw.copy()\n",
        "\n",
        "print(df_raw.shape)\n",
        "df_raw.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EututNaSxusF"
      },
      "source": [
        "Data Documentation\n",
        "* There is no official data documentation, however Kmart is an online retailer in the US.\n",
        "* The understanding is that:\n",
        "  * The dataset shows **sales levels in 2019**. The sales results is made by the composition of its annual customer online orders.\n",
        "  * The data is broke down by product, order date, order id, quantity, unitary price (likely in US$), and customer address\n",
        "  * **Each row** is a product bought in a given order. A customer order is represented by a set of Order ID "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfBMy_MQzn8V"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YRAuPodunqK"
      },
      "source": [
        "# Quick EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tt2K9TYb_2Z4"
      },
      "source": [
        "Check and handle:\n",
        "* Missing data\n",
        "* Duplicates\n",
        "* Junk Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBRJkLPUBkNP"
      },
      "source": [
        "### Missing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suU5Tg5GvdiE"
      },
      "source": [
        "* There are missing data, but it is small (545) compared to the total rows (186k) - 0.28%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "1_tnKXPvyoEk",
        "outputId": "2bec0bd1-c9d9-4485-948d-844ef027b7fb"
      },
      "outputs": [],
      "source": [
        "missing_data = df.isna().sum().sort_values(ascending=False) \n",
        "pd.DataFrame(data= {\"Absolute Levels\": missing_data,\n",
        "                    \"Relative Levels (%)\": round(missing_data / len(df) * 100 , 2)\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqaQRQvFxtXi"
      },
      "source": [
        "Inspect missing data dataframe\n",
        "* It looks that missing values happen in all columns in a set of rows\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "4JEj6o9Qxk-Q",
        "outputId": "ff0321d5-6e1d-41a2-b543-4a60200e5a6f"
      },
      "outputs": [],
      "source": [
        "df_na = df[df.isna().any(axis=1)].copy()\n",
        "df_na.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOmFeQ83yJ35"
      },
      "source": [
        "Missing values happen in all columns in a set of rows\n",
        "* it is 0 non-null in all columns\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywggcW6zyFmM",
        "outputId": "524f83d6-125b-4748-cb9a-2f8a0d7d2c92"
      },
      "outputs": [],
      "source": [
        "df_na.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8yPYg_Yzg5y"
      },
      "source": [
        "Just as an exploratory exercise: in which months has it happened?\n",
        "* Assumption: We are taking the indices from `df_na` and substracting 1, so we can get predecessor datapoint, which hopefully doesn't have missing data. \n",
        "* If predecessor has missing data, we iterate on getting its predecessor\n",
        "* By using `.isna().sum()`, we not there is not missing data in the predecessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzAyqt3Sz7KZ",
        "outputId": "0705ebe8-52b0-4e19-ee88-acf00bad22f1"
      },
      "outputs": [],
      "source": [
        "df.loc[df_na.index - 1].isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8qo4Hv40sJ5"
      },
      "source": [
        "Let's filter date on `df.loc[df_na.index - 1]` , extract month and plot its distribution\n",
        "* The missing values happen across all months\n",
        "* There is 'or' level for month, which looks to be junk data. We will ignore that for a moment, since this data comes from the missing values predecessor. We will explore junk data in a moment "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "HFEP8Aq_0z2V",
        "outputId": "fd8b1e84-e610-4f25-f285-6e0cd4727d82"
      },
      "outputs": [],
      "source": [
        "df_date_na = df.loc[df_na.index - 1].filter(['Order Date'], axis=1)\n",
        "df_date_na['Month'] = df_date_na['Order Date'].apply(lambda x: x[:2]) # extracts month from pattern mm/dd/yy HH:MM\t\n",
        "\n",
        "sns.countplot(data=df_date_na,x='Month')\n",
        "plt.show()\n",
        "del df_date_na, df_na"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFDf82EW4rvY"
      },
      "source": [
        "So what? The analysis indicates: \n",
        "* For some reason there is missing data happening all over the year. In the workplace, this information would be taken to the data engineering team, so it can be further investigated the root causes and potential solutions\n",
        "* **For our project purpose, we will remove these missing data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_6r9DiT59aM",
        "outputId": "efadfc4b-4cfa-4c38-d6cc-8b069c7c7dd8"
      },
      "outputs": [],
      "source": [
        "df.dropna(inplace=True)\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKmiIWkaBp1u"
      },
      "source": [
        "### Duplicates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6RznDU582vP"
      },
      "source": [
        "* We note what looks to be junk data (like index 1102) and real duplicates, we will first manage junk data, then get back to duplicates\n",
        "* A junk row looks to be \"all junked\", meaning all columns there are junk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "U2jQdNfZ823h",
        "outputId": "4508e126-ac52-4dfc-db3c-2a063a36a122"
      },
      "outputs": [],
      "source": [
        "df[df.duplicated()] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SV4J2stBsxR"
      },
      "source": [
        "### Junk Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjmvXiSEvgJf"
      },
      "source": [
        "Quick EDA with Pandas Profiling\n",
        "* No missing data, as expected\n",
        "* Junk data on `Order ID, Quanrtity Ordered, Order Date, Purchase Address`\n",
        "* We will explore other variables distribution in detail in another moment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AG7ieS1up8D"
      },
      "outputs": [],
      "source": [
        "from pandas_profiling import ProfileReport\n",
        "pandas_report = ProfileReport(df=df, minimal=True)\n",
        "pandas_report.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fl2iallP-5UI"
      },
      "source": [
        "Get rid of junk data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "KNlImhjVHCZW",
        "outputId": "637bb9ca-0c64-4ea2-fd89-f7db7ed55b03"
      },
      "outputs": [],
      "source": [
        "df = df.query('`Order ID` != \"Order ID\"') \n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqR4WstpRt5I"
      },
      "source": [
        "No junk data anymore on `Order ID, Quanrtity Ordered, Order Date, Purchase Address`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dH3i9AcQ-t4h"
      },
      "outputs": [],
      "source": [
        "pandas_report = ProfileReport(df=df, minimal=True)\n",
        "pandas_report.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VaqFj7UBwCP"
      },
      "source": [
        "### Back to Duplicates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tK_phmnA-7pS"
      },
      "source": [
        "Check duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "anwsPJWo-9Sh",
        "outputId": "5c219b4f-0b69-4424-a337-6c11aa75e1dd"
      },
      "outputs": [],
      "source": [
        "df[df.duplicated()] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Q_5GinG_ReD"
      },
      "source": [
        "Sanity check for first row indicated in the previous table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "WjX8Ijy9_CI8",
        "outputId": "aff56caa-c390-484b-de94-e84189b1bb34"
      },
      "outputs": [],
      "source": [
        "df.loc[873:877,:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DygWVPL2_YkC"
      },
      "source": [
        "Drop duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "m6vmVjyp_azn",
        "outputId": "4d40eed8-ef9d-41b9-b552-69306c2e1904"
      },
      "outputs": [],
      "source": [
        "df = df.drop_duplicates(keep='first').reset_index(drop=True)\n",
        "\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OY9-U4KQ_wxR"
      },
      "source": [
        "No duplicates anymore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "Oddo4lyV_o4j",
        "outputId": "dfdcf470-853d-4b2c-9612-2179863dc51f"
      },
      "outputs": [],
      "source": [
        "df[df.duplicated()] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOWawXRcupNh"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXZ3o8TcAdP4"
      },
      "source": [
        "# More EDA and Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4omqMPgYBMQC"
      },
      "source": [
        "* Convert Data Type\n",
        "* Feature engineering\n",
        "  * Extract Information from date\n",
        "  * Compute revenue\n",
        "  * Add product line\n",
        "  * Add synthetic cost and compute margin\n",
        "  * Customer Address"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXAFthbLBynT"
      },
      "source": [
        "### Convert Data Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zZgb3LrAku9",
        "outputId": "0e248430-ce88-4dd5-c89f-482f46563773"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKwStzFvBDf0"
      },
      "source": [
        "Convert\n",
        "* Price and Quantity to number\n",
        "* Order Date to datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ds8NWhBCuB-h",
        "outputId": "b04e62df-640a-47c4-e685-de2596e52c66"
      },
      "outputs": [],
      "source": [
        "df['Price Each'] = df['Price Each'].astype(float)\n",
        "df['Quantity Ordered'] = df['Quantity Ordered'].astype(int)\n",
        "df['Order Date'] = pd.to_datetime(df['Order Date'])\n",
        "\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xvk4nr8tK7Ih"
      },
      "source": [
        "### Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R24mhwbULDXY"
      },
      "source": [
        "#### Extract date information using `feature-engine`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "KUA1ViTtJZwg",
        "outputId": "99a4515c-2fde-45f5-fe3f-f0725a5c523e"
      },
      "outputs": [],
      "source": [
        "from feature_engine.datetime import DatetimeFeatures\n",
        "pd.set_option('display.max_columns', None)\n",
        "df = DatetimeFeatures(variables=['Order Date'], features_to_extract='all', drop_original=False).fit_transform(df)\n",
        "df['Weekday'] =  df['Order Date'].dt.day_name()\n",
        "df['YearMonth'] = df['Order Date'].dt.to_period('M')\n",
        "df['YearQuarter'] = df['Order Date'].dt.to_period('Q')\n",
        "\n",
        "# drop variables apparently not relevant for the project\n",
        "df.drop(['Order Date_month_start', 'Order Date_month_end', 'Order Date_quarter_start',\n",
        "         'Order Date_quarter_end', 'Order Date_year_start', 'Order Date_year_end',\n",
        "         'Order Date_leap_year', 'Order Date_days_in_month', 'Order Date_second']\n",
        "        ,axis=1, inplace=True)\n",
        "\n",
        "print(df.shape)\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dRbVkZq_pHN"
      },
      "source": [
        "Check if all data is related to 2019\n",
        "* Only 34 purchases in 2020"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1UkFMtl_d2r",
        "outputId": "8f32627e-4644-4a83-8721-bd7f6e47258d"
      },
      "outputs": [],
      "source": [
        "df['Order Date_year'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWy-V8QSAVPK"
      },
      "source": [
        "Check which days of the month and hours were these 2020 purchases\n",
        "* Day 1, from 0h to 5h\n",
        "  * Maybe the customer took the decision to buy before midnight but bought after midnight? (Common dilemma in e-commerce) \n",
        "  * For the sake of assessment, we will consider purchases that were closed in 2019"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8Idl9KR_2KE",
        "outputId": "61add86a-8f0c-4c66-8bb7-2c5264cb0a5d"
      },
      "outputs": [],
      "source": [
        "df.query('`Order Date_year` == 2020')[['Order Date_day_of_month','Order Date_hour' ]].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qq8obFJP_vsO"
      },
      "source": [
        "For the sake of the assessment, we remove 2020"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHMr3DJQA-FT",
        "outputId": "cf6ec92b-b443-41b5-c5f1-2ce48b3159bb"
      },
      "outputs": [],
      "source": [
        "df = df.query('`Order Date_year` == 2019')\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sros_neoLIG1"
      },
      "source": [
        "Add flag for US Holidays\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKKH6VqOCR3a",
        "outputId": "46442f4f-0741-4692-f304-b6b35e502bf3"
      },
      "outputs": [],
      "source": [
        "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
        "holidays = USFederalHolidayCalendar().holidays(start='2019-01-01', end='2020-01-05')\n",
        "holidays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "YNrKd0DxMWY5",
        "outputId": "67a43b74-6f1e-4414-c138-f0684f35fa47"
      },
      "outputs": [],
      "source": [
        "df['HolidayFlag'] = pd.to_datetime(df['Order Date'].dt.strftime('%Y-%m-%d')).apply(lambda x: True if x in holidays else False)\n",
        "\n",
        "pd.DataFrame(data={\"Count\":df['HolidayFlag'].value_counts(),\n",
        "                   \"Relative %\": round(df['HolidayFlag'].value_counts(normalize=True)*100 ,1)\n",
        "                   })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZsJ1YUwPNaX"
      },
      "source": [
        "#### Compute Revenue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-AXL0LOPc29"
      },
      "outputs": [],
      "source": [
        "df['Revenue'] = df['Quantity Ordered'] * df['Price Each']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "lq1GBBaNPTHz",
        "outputId": "c6cb7eca-8a33-4ec5-b85a-16de8e603271"
      },
      "outputs": [],
      "source": [
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Uw3Gx0J2Eyq"
      },
      "source": [
        "#### Add product line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0nvz_ix2GSu",
        "outputId": "079f79eb-a150-4c17-e3fc-a0da56ba14ce"
      },
      "outputs": [],
      "source": [
        "np.sort(df['Product'].unique()).tolist() # so I can copy and paste to create dictionary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFs2-w5K2gAS"
      },
      "source": [
        "Map Product and Product line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vbw9odhv2e9A"
      },
      "outputs": [],
      "source": [
        "dict_prod_line = {'20in Monitor': \"PC and Video Games\",\n",
        "                  '27in 4K Gaming Monitor': \"PC and Video Games\",\n",
        "                  '27in FHD Monitor': \"PC and Video Games\",\n",
        "                  '34in Ultrawide Monitor': \"PC and Video Games\",\n",
        "                  'AA Batteries (4-pack)': \"Cable and Accessories\",\n",
        "                  'AAA Batteries (4-pack)': \"Cable and Accessories\",\n",
        "                  'Apple Airpods Headphones': \"Audio\",\n",
        "                  'Bose SoundSport Headphones': \"Audio\",\n",
        "                  'Flatscreen TV': \"TV\",\n",
        "                  'Google Phone': \"Mobile\",\n",
        "                  'LG Dryer': \"Household\",\n",
        "                  'LG Washing Machine': \"Household\",\n",
        "                  'Lightning Charging Cable': \"Cable and Accessories\",\n",
        "                  'Macbook Pro Laptop': \"Computer and Laptop\",\n",
        "                  'ThinkPad Laptop': \"Computer and Laptop\",\n",
        "                  'USB-C Charging Cable': \"Cable and Accessories\",\n",
        "                  'Vareebadd Phone': \"Mobile\",\n",
        "                  'Wired Headphones': \"Audio\",\n",
        "                  'iPhone': \"Mobile\"\n",
        "                  }\n",
        "# dict_prod_line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "s5EP6gCa2z70",
        "outputId": "0d768794-312a-4594-a8fd-2200044fedfb"
      },
      "outputs": [],
      "source": [
        "df['ProductLine'] = df['Product'].map(dict_prod_line)\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAmFXO-27Oik"
      },
      "source": [
        "#### Add synthetic cost and compute margin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8moGaBhRPRK-"
      },
      "source": [
        "\n",
        "* **Reason** bring the use case to analyze margin\n",
        "  * We will simplify that `Margin = Revenue - Cost`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyOSoqE6TaSN"
      },
      "source": [
        "Is the price constant for all products?\n",
        "* Yes, since standard deviation is 0. \n",
        "* We will follow this pattern, so the individual product cost will be constant as well"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjKOjMlCPUf2",
        "outputId": "85be7ffb-8584-44d3-c5ab-a03548c5e0fa"
      },
      "outputs": [],
      "source": [
        "df.groupby(['Product'])['Price Each'].std()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aY6TIoq06VO"
      },
      "source": [
        "What is the price for each product, colored by product line?\n",
        "* Computer and Laptop, Mobile and Household tend to be more expensive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "l8b-BS1B1kCJ",
        "outputId": "85867666-707d-482d-fd32-82f800693349"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(17, 4))\n",
        "sns.barplot(data = df.groupby(['Product','ProductLine'])['Price Each'].median().sort_values(ascending=False).reset_index(),\n",
        "            x = \"Product\", y = \"Price Each\", hue = \"ProductLine\", dodge = False)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5B4cC3zAPVF"
      },
      "source": [
        "Create product cost dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mw0vBl_A9zMA"
      },
      "outputs": [],
      "source": [
        "dict_prod_cost = {'20in Monitor': 50,\n",
        "                  '27in 4K Gaming Monitor': 175,\n",
        "                  '27in FHD Monitor': 70,\n",
        "                  '34in Ultrawide Monitor': 180,\n",
        "                  'AA Batteries (4-pack)': 1.2,\n",
        "                  'AAA Batteries (4-pack)': 1.1,\n",
        "                  'Apple Airpods Headphones': 45,\n",
        "                  'Bose SoundSport Headphones': 40,\n",
        "                  'Flatscreen TV': 170,\n",
        "                  'Google Phone': 400,\n",
        "                  'LG Dryer': 400,\n",
        "                  'LG Washing Machine': 300,\n",
        "                  'Lightning Charging Cable': 4,\n",
        "                  'Macbook Pro Laptop': 500,\n",
        "                  'ThinkPad Laptop': 350,\n",
        "                  'USB-C Charging Cable': 3.8,\n",
        "                  'Vareebadd Phone': 250,\n",
        "                  'Wired Headphones': 4.5,\n",
        "                  'iPhone': 300, \n",
        "                  }\n",
        "# dict_prod_cost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKddzP-KAMaf"
      },
      "source": [
        "Map cost based on product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "4CzMFh4k-PVt",
        "outputId": "a7187e7e-9154-4711-c066-ddfe57e21aa1"
      },
      "outputs": [],
      "source": [
        "df['ProductCostEach'] = df['Product'].map(dict_prod_cost)\n",
        "df['Cost'] = df['ProductCostEach'] * df['Quantity Ordered']\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2j7yOocAR_C"
      },
      "source": [
        "Compute absolute margin (`Margin = Revenue - Cost`) and Percentual Margin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "OiRFnKZt-idt",
        "outputId": "3c1bf52a-8188-47a4-d856-101230b2559b"
      },
      "outputs": [],
      "source": [
        "df['Margin'] = df['Revenue'] - df['Cost']\n",
        "df['PercentualMargin'] = round(df['Margin'] / df['Revenue'] * 100, 2)\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a62v6Rfb-i1G"
      },
      "source": [
        "#### Customer Address"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "5Q5AcBBFAdPZ",
        "outputId": "770041e1-2eed-4715-cd10-6afde6c86062"
      },
      "outputs": [],
      "source": [
        " df[['Purchase Address']].head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bswJbrTAdYj"
      },
      "source": [
        "We are interested in taking US State Abbreviations (that happens after the last comma), and the city (happens in second last comma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "RsBW4-BH-jm6",
        "outputId": "d6a28a63-9db6-4a8a-93ed-8881966f0789"
      },
      "outputs": [],
      "source": [
        "df['State'] = df['Purchase Address'].apply(lambda x: x.split(\",\")[-1][1:3])\n",
        "df['City'] = df['Purchase Address'].apply(lambda x: x.split(\",\")[-2][1:])\n",
        "df['City'] = df['State'] + \" , \" + df['City']\n",
        "\n",
        "print(df.shape)\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtQZDyACPVjD"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMgGZoHhPpvv"
      },
      "source": [
        "# Save processed data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsWA3L-LQoWM"
      },
      "source": [
        "* For simplicity, I ran the notebook on Colab, saved the data in the session, downloaded manually the data to my laptop, then updloaded to the GitHub Repo\n",
        "* In the workplace, the notebook session would be connected directly to the repo, either running in a local IDE (ie: VS Code) or cloud IDE (ie.: Gitpod), and a more professional approach to persist the data be usedPersist data to inputs/dataset folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HufDVj6QPp4D"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"kmart_processed_data.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8W7Qpx0NtnZg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucOPXh9v9iCv"
      },
      "source": [
        "# Pipeline to process raw data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siCoum3D9oCm"
      },
      "source": [
        "In the workplace, an application will fetch the raw data and a piece of code would process it, so the data can be used by subsequent tasks/applications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "ZPoBZTcv9j4s",
        "outputId": "ff049e15-fe5a-4f4d-e6a7-f11bb5c68f80"
      },
      "outputs": [],
      "source": [
        "print(df_raw.shape)\n",
        "df_raw.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m--AKnoC92qa"
      },
      "source": [
        "The data processes in the notebook include:\n",
        "* Drop missing values\n",
        "* Get rid of junk data\n",
        "* Drop duplicated rows \n",
        "* Convert data type\n",
        "* Extract information from order date\n",
        "* Compute revenue\n",
        "* Add product line\n",
        "* Add cost and compute margin\n",
        "* Extract information from customer address\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-QGltK4-E9U"
      },
      "source": [
        "The code below contains: \n",
        "* Custom transformers used to transform the data inside the pipeline\n",
        "* Pipeline steps for data processing\n",
        "\n",
        "\n",
        "**Note**\n",
        "* the variables names and dictionaries would likely live in a config file\n",
        "* for the purpose of the assessment, I hard coded here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "8sJ-x8T299ea",
        "outputId": "12236a0d-702c-418c-fdf0-b6ad966ea347"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn import set_config\n",
        "set_config(display=\"diagram\") \n",
        "import pandas as pd\n",
        "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "from feature_engine.imputation import DropMissingData\n",
        "from feature_engine.datetime import DatetimeFeatures\n",
        "\n",
        "############################################################\n",
        "#### Custom transformers to be added to the pipeline\n",
        "############################################################\n",
        "class GetRidJunkData(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self, variables):\n",
        "    if not isinstance(variables, list): self.variables = [variables]\n",
        "    else: self.variables = variables\n",
        "\n",
        "  def fit(self, X, y=None): return self\n",
        "      \n",
        "  def transform(self, X):\n",
        "    for feature in self.variables:\n",
        "      X = X.query(f'`{feature}` != \"{feature}\"')\n",
        "    return X\n",
        "\n",
        "\n",
        "class DropDuplicatedRows(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self): return None\n",
        "\n",
        "  def fit(self, X, y=None): return self\n",
        "      \n",
        "  def transform(self, X):\n",
        "    X = X.drop_duplicates(keep='first').reset_index(drop=True)\n",
        "    return X\n",
        "\n",
        "class ConverDataType(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self): return None\n",
        "\n",
        "  def fit(self, X, y=None): return self\n",
        "      \n",
        "  def transform(self, X):\n",
        "    X['Price Each'] = X['Price Each'].astype(float)\n",
        "    X['Quantity Ordered'] = X['Quantity Ordered'].astype(int)\n",
        "    X['Order Date'] = pd.to_datetime(X['Order Date'])\n",
        "    return X\n",
        "\n",
        "\n",
        "class ExtractInformationFromDate(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self, variables):\n",
        "    if not isinstance(variables, list): self.variables = [variables]\n",
        "    else: self.variables = variables\n",
        "\n",
        "  def fit(self, X, y=None): return self\n",
        "      \n",
        "  def transform(self, X):\n",
        "    for feature in self.variables:\n",
        "      X = DatetimeFeatures(variables=[feature], features_to_extract='all', drop_original=False).fit_transform(X)\n",
        "      X['Weekday'] = X[feature].dt.day_name()\n",
        "      X['YearMonth'] = X['Order Date'].dt.to_period('M')\n",
        "      X['YearQuarter'] = X['Order Date'].dt.to_period('Q')\n",
        "      \n",
        "      X.drop([f'{feature}_month_start', f'{feature}_month_end', f'{feature}_quarter_start',\n",
        "         f'{feature}_quarter_end', f'{feature}_year_start', f'{feature}_year_end',\n",
        "         f'{feature}_leap_year', f'{feature}_days_in_month', f'{feature}_second']\n",
        "        ,axis=1, inplace=True)\n",
        "      \n",
        "      X = X.query(f'`{feature}_year` == 2019')\n",
        "      \n",
        "      holidays = USFederalHolidayCalendar().holidays(start='2019-01-01', end='2020-01-05')\n",
        "      X['HolidayFlag'] = pd.to_datetime(X[feature].dt.strftime('%Y-%m-%d')).apply(lambda x: True if x in holidays else False)\n",
        "\n",
        "    return X\n",
        "\n",
        "\n",
        "class ComputeRevenue(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self): return None\n",
        "\n",
        "  def fit(self, X, y=None): return self\n",
        "      \n",
        "  def transform(self, X):\n",
        "    X['Revenue'] = X['Quantity Ordered'] * X['Price Each']\n",
        "    return X\n",
        "\n",
        "\n",
        "class AddProductLine(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self):\n",
        "    self.dict_prod_line = {'20in Monitor': \"PC and Video Games\",\n",
        "                          '27in 4K Gaming Monitor': \"PC and Video Games\",\n",
        "                          '27in FHD Monitor': \"PC and Video Games\",\n",
        "                          '34in Ultrawide Monitor': \"PC and Video Games\",\n",
        "                          'AA Batteries (4-pack)': \"Cable and Accessories\",\n",
        "                          'AAA Batteries (4-pack)': \"Cable and Accessories\",\n",
        "                          'Apple Airpods Headphones': \"Audio\",\n",
        "                          'Bose SoundSport Headphones': \"Audio\",\n",
        "                          'Flatscreen TV': \"TV\",\n",
        "                          'Google Phone': \"Mobile\",\n",
        "                          'LG Dryer': \"Household\",\n",
        "                          'LG Washing Machine': \"Household\",\n",
        "                          'Lightning Charging Cable': \"Cable and Accessories\",\n",
        "                          'Macbook Pro Laptop': \"Computer and Laptop\",\n",
        "                          'ThinkPad Laptop': \"Computer and Laptop\",\n",
        "                          'USB-C Charging Cable': \"Cable and Accessories\",\n",
        "                          'Vareebadd Phone': \"Mobile\",\n",
        "                          'Wired Headphones': \"Audio\",\n",
        "                          'iPhone': \"Mobile\"\n",
        "                          }\n",
        "\n",
        "  def fit(self, X, y=None): return self\n",
        "      \n",
        "  def transform(self, X):\n",
        "    X['ProductLine'] = X['Product'].map(self.dict_prod_line)\n",
        "    return X\n",
        "\n",
        "\n",
        "class AddCostAndComputeMargin(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self):\n",
        "    self.dict_prod_cost = {'20in Monitor': 50,\n",
        "                          '27in 4K Gaming Monitor': 175,\n",
        "                          '27in FHD Monitor': 70,\n",
        "                          '34in Ultrawide Monitor': 180,\n",
        "                          'AA Batteries (4-pack)': 1.2,\n",
        "                          'AAA Batteries (4-pack)': 1.1,\n",
        "                          'Apple Airpods Headphones': 45,\n",
        "                          'Bose SoundSport Headphones': 40,\n",
        "                          'Flatscreen TV': 170,\n",
        "                          'Google Phone': 400,\n",
        "                          'LG Dryer': 400,\n",
        "                          'LG Washing Machine': 300,\n",
        "                          'Lightning Charging Cable': 4,\n",
        "                          'Macbook Pro Laptop': 500,\n",
        "                          'ThinkPad Laptop': 350,\n",
        "                          'USB-C Charging Cable': 3.8,\n",
        "                          'Vareebadd Phone': 250,\n",
        "                          'Wired Headphones': 4.5,\n",
        "                          'iPhone': 300, \n",
        "                          }\n",
        "\n",
        "  def fit(self, X, y=None): return self\n",
        "      \n",
        "  def transform(self, X):\n",
        "    X['ProductCostEach'] = X['Product'].map(self.dict_prod_cost)\n",
        "    X['Cost'] = X['ProductCostEach'] * X['Quantity Ordered']\n",
        "    X['Margin'] = X['Revenue'] - X['Cost']\n",
        "    X['PercentualMargin'] = round(X['Margin'] / X['Revenue'] * 100, 2)\n",
        "    return X\n",
        "\n",
        "\n",
        "class ExtractAddressInformation(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self, variables):\n",
        "    if not isinstance(variables, list): self.variables = [variables]\n",
        "    else: self.variables = variables\n",
        "\n",
        "  def fit(self, X, y=None): return self\n",
        "      \n",
        "  def transform(self, X):\n",
        "    for feature in self.variables:\n",
        "      X['State'] = X['Purchase Address'].apply(lambda x: x.split(\",\")[-1][1:3])\n",
        "      X['City'] = X['Purchase Address'].apply(lambda x: x.split(\",\")[-2][1:])\n",
        "      X['City'] = X['State'] + \" , \" + X['City']\n",
        "\n",
        "    return X\n",
        "\n",
        "\n",
        "\n",
        "############################################################\n",
        "#### Pipeline for data processing\n",
        "############################################################\n",
        "def PipelineDataProcessing():\n",
        "  pipeline_base = Pipeline([\n",
        "      \n",
        "      (\"DropMissingData\",DropMissingData() ),\n",
        "      (\"GetRidJunkData\", GetRidJunkData(variables=['Order ID']) ),\n",
        "      (\"DropDuplicatedRows\", DropDuplicatedRows() ),\n",
        "      (\"ConverDataType\", ConverDataType()), \n",
        "      (\"ExtractInformationFromDate\", ExtractInformationFromDate(variables='Order Date')),\n",
        "      (\"ComputeRevenue\", ComputeRevenue() ),\n",
        "      (\"AddProductLine\", AddProductLine() ),\n",
        "      (\"AddCostAndComputeMargin\", AddCostAndComputeMargin() ),\n",
        "      (\"ExtractAddressInformation\", ExtractAddressInformation(variables= ['Purchase Address']))\n",
        "\n",
        "    ])\n",
        "\n",
        "  return pipeline_base\n",
        "\n",
        "PipelineDataProcessing()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFFMt08v-Ixl"
      },
      "source": [
        "Transform the data based on the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "I0pOcigb-NDD",
        "outputId": "9e7193f2-9e47-47f8-efc5-db517d93632d"
      },
      "outputs": [],
      "source": [
        "df_kmart = PipelineDataProcessing().fit_transform(df_raw)\n",
        "print(df_kmart.shape)\n",
        "df_kmart.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1rLAkIc-N3O"
      },
      "source": [
        "Sanity test: Is `df_kmart` the same as `df` (dataset we have been transforming thru the notebook)?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLAZBPNY-Yt-",
        "outputId": "28e143c7-6a38-4b99-b734-6c287b9ee0d3"
      },
      "outputs": [],
      "source": [
        "df.equals(df_kmart)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTaERtB59kTD"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Data Collection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.3 ('env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "orig_nbformat": 2,
    "vscode": {
      "interpreter": {
        "hash": "3bcaed28d2114d94f3f64a167e0e2ef9c6ffa8786993d4a37480c1279e63da41"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
